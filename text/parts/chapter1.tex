\chapter{Обзор существующих методов}
\label{chapter_review}

Формально имеется набор $\{v_1, ..., v_n\}$ из $n$ параметров ЭА, каждый из которых может принимать $\{v_{i1}, .., v_{im}\}$ значения. Это могут быть как дискретные значения, так и интервалы значений. Целью алгоритма является выбор таких значений параметров $v_i$, чтобы повысить эффективность ЭА.

Большинство методов адаптивной настройки параметров ЭА можно отнести к классу сопоставителей вероятностей (probability matching techniques), в которых вероятность выбора значения параметра пропорциональна его качеству.

\subsection{Марковский процесс выбора}

\section{Обучение с подкреплением}
\label{rl}
Алгоритмы обучения с подкреплением часто используется для выбора стратегий в интерактивной среде. Большинство таких алгоритмов не требуют заранее подобранных тестовых примеров, так как их обучение происходит одновременно с применением накопленного опыта.

\begin{figure}
    \centering
    \includegraphics[width=0.6\textwidth]{rl-scheme.png}
    \caption{Схема алгоритма обучения с подкреплением.}
    \label{rl_scheme}
\end{figure}

Принцип работы алгоритма обучения с подкреплением представлен на схеме~\ref{rl_scheme}. Среда находится в некотором состоянии, которое имеет некоторый набор действий. Агент воздействует на среду, выбирая одно из возможных действий и применяя его к среде. В следствие этого среда может перейти в новое состояние. За выбранное действие агент получает награду. Награда выражается вещественнозначным числом. Награда может быть отрицательна в случае штрафа. Задачей агента является максимизация суммарной награды.

Чтобы поставить задачу необходимо ...

Есть обучение с построением модели и обучение без модели

Обучение с моделью (Dyna, ... ) не слишком хорошо себя показывали в общих задачах.. (весьма специализированные

\subsection{Q-обучение}

Это обучение без модели. $\epsilon$-жадная стратегия. Delayed q-learning

\section{Модель UTree}

\subsection{Критерий типа Колмогорова-Смирнова}
\label{ks_criteria}
В статистическом анализе используют различные критерии однородности для проверки гипотезы о принадлежности двух независимых выборок одному закону распределения. Одним из наиболее используемых непараметрических критериев о проверке однородности двух эмпирических законов распределения является критерий однородности Смирнова.

Эмпирическая функция распределения является приближением теоретической функции распределения, построенное с помощью выборки из него. Пусть $\{X_i\}_{i = 1}^n$ выборка из случайной величины $X$, объема $n$. Эмпирической функцией распределения случайной величины $X$ называется случайная величина $F(x) = \frac{1}{n}\sum\limits_{i = 1}^n{H(x - X_i)}$, где $H$~-- функция Хевисайда. По сути заданная таким образом функция распределения в точке $x$ равна частоте элементов выборки, не превосходящих $x$.

\begin{figure}
    \centering
    \includegraphics[width=0.6\textwidth]{ks.png}
    \caption{График $F_{a, n}$ и $F_{b, m}$}
    \label{ks}
\end{figure}

Критерий позволяет найти точку, в которой сумма накопленных частот расхождений наибольшая, и оценить достоверность этого расхождения. В качестве нулевой гипотезы $H_0$ принимается, что две исследуемые выборки подчиняются одному закону распределения случайной величины. Для двух независимых выборок $a$ и $b$, объемами $n$ и $m$ соответственно, строятся эмпирические функции распределения $F_{a, n}$ и $F_{b, m}$. Затем считается значение $\sqrt{\frac{nm}{n + m}}D_{n, m}$, где $D_{n, m} = \sup\limits_x|F_{a, n}(x) - F_{b, m}(x)|$. Если рассчитанное значение превышает квантиль распределения Колмогорова $K_{\alpha}$ для заданного уровня значимости $\alpha$, то нулевая гипотеза $H_0$ отвергается.

\section{Метод, предложенный Karafotias}
Метод настройки параметров с помощью обучения с подкреплением.

\section{Метод Earpc}


\section{Модельная задача}

\subsection{Выводы}

