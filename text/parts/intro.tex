\startprefacepage

Эффективность работы эволюционного алгоритма зависит от выбора значений его параметров. Подбор параметров может осуществляться до запуска эволюционного алгоритма. Однако оптимальные значения параметров могут изменяться в ходе работы алгоритма. Поэтому необходим метод адаптивной настройки параметров в процессе оптимизации. 

Значения параметров эволюционного алгоритма лежат в заданном интервале значений. Задачу выбора значений параметров дискретизируют, разделяя диапазон допустимых значений параметра на интервалы. Разбиение на интервалы может производиться до запуска алгоритма и не меняться в процессе его работы. Однако изменение разбиения во время работы способствует улучшению работы алгоритма.

Существуют алгоритмы адаптивной настройки параметров эволюционного алгоритма, в которых вероятность выбора значения параметра пропорциональна эффективности его применения. Одним из таких алгоритмов является \textit{EARPC}. В данном методе интервал допустимых значений разбивается в ходе работы алгоритма. Также существует метод настройки параметров эволюционного алгоритма с помощью обучения с подкреплением. Однако в данном подходе разбиение диапазона допустимых значений производится до запуска алгоритма. 

В данной работе предлагаются два метода адаптивной настройки параметров эволюционного алгоритма. Один из них является улучшением существующего метода настройки параметров с помощью обучения с подкреплением за счет разбиения диапазона допустимых значений параметра в ходе работы алгоритма при помощи алгоритма \textit{EARPC}. Второй метод основан на применении  \textit{Q}-обучения с адаптивным выделением множества действий агента. 