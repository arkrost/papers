\startconclusionpage

В работе предложены два метода адаптивной настройки параметров эволюционных алгоритмов с помощью обучения с подкреплением. В данных алгоритмах множество действий агента формировалось в процессе оптимизации, за счет разбиения диапазона допустимых значений параметра в ходе работы алгоритма. Один из предложенных алгоритмов был основан на двух существующих подходах к настройке параметров ЭА: алгоритме \textit{EARPC} и методе, предложенном \textit{Karafotias et al}. Второй алгоритм основан на том, что диапазон допустимых значений настраеваемого параметра переразбивается в случае, когда значения ожидаемой награды примерно равны для всех действий агента. 

Предложенные методы адаптивной настройки параметров эволюционных алгоритмов были протестированы на четырех модельных задачах. Было проведено сравнение предложенных методов с существующими алгоритмами настройки параметров ЭА. Наилучшие результаты были получены при использовании метода с переразбиением диапазона значений настраеваемого параметра. Было продемонстрировано, что данный метод улучшает значения настраеваемых параметров на протяжении всего процесса оптимизации в отличие от остальных рассмотренных методов.

Таким образом была экспериментально проверена эффективность использования предложенного метода адаптивной настройки параметров эволюционных алгоритмов. Разработанный алгоритм удовлетворяет всем поставленным требованиям.
